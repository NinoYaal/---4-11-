{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(train_path=\"data_set/train.csv\", test_path=\"data_set/test1.csv\"):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    \n",
    "    df1 = train.drop([\"Unnamed: 0\"], axis=1)\n",
    "    df2 = test.drop([\"Unnamed: 0\"], axis=1)\n",
    "    df2[\"label\"] = -1\n",
    "    \n",
    "    for col in [\"android_id\", \"apptype\", \"carrier\", \"ntt\", \"media_id\", \"cus_type\", \"package\", \"location\"]:\n",
    "        df1[col] = df1[col].astype(\"category\")\n",
    "        df2[col] = df2[col].astype(\"category\")\n",
    "        \n",
    "    for col in [\"fea_hash\"]:\n",
    "        df1[col] = df1[col].map(lambda x: 0 if len(str(x)) > 16 else int(x))\n",
    "        df2[col] = df2[col].map(lambda x: 0 if len(str(x)) > 16 else int(x))\n",
    "        \n",
    "    for col in [\"dev_height\", \"dev_ppi\", \"dev_width\", \"fea_hash\", \"fea1_hash\",\"label\"]:\n",
    "        df1[col] = df1[col].astype(\"int64\")\n",
    "        df2[col] = df2[col].astype(\"int64\")\n",
    "        \n",
    "    df1[\"time\"] = pd.to_datetime(df1[\"timestamp\"], unit=\"ms\", origin=pd.Timestamp(\"1970-01-01\"))\n",
    "    df2[\"time\"] = pd.to_datetime(df2[\"timestamp\"], unit=\"ms\", origin=pd.Timestamp(\"1970-01-01\"))\n",
    "    \n",
    "    df1[\"day\"] = df1.time.dt.day\n",
    "    df2[\"day\"] = df2.time.dt.day\n",
    "\n",
    "    df1[\"hour\"] = df1.time.dt.hour\n",
    "    df2[\"hour\"] = df2.time.dt.hour\n",
    "\n",
    "    df1[\"minute\"] = df1.time.dt.minute\n",
    "    df2[\"minute\"] = df2.time.dt.minute\n",
    "\n",
    "    df1.set_index(\"sid\", drop=True, inplace=True)\n",
    "    df2.set_index(\"sid\", drop=True, inplace=True)\n",
    "    \n",
    "    df1.dev_height[df1.dev_height == 0] = None\n",
    "    df1.dev_width[df1.dev_width == 0] = None\n",
    "    df1.dev_ppi[df1.dev_ppi == 0] = None\n",
    "    df2.dev_height[df2.dev_height == 0] = None\n",
    "    df2.dev_width[df2.dev_width == 0] = None\n",
    "    df2.dev_ppi[df2.dev_ppi == 0] = None\n",
    "    return df1, df2\n",
    "\n",
    "def process_cate(df1,df2,col):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    \n",
    "    df1[col] = le.fit_transform(df1[col])\n",
    "    df1[col] = df1[col].astype(\"category\")\n",
    "    df2[col] = le.transform(df2[col])\n",
    "    df2[col] = df2[col].astype(\"category\")\n",
    "    return df1, df2\n",
    "\n",
    "def dict_cate(df1,df2,col,dic):\n",
    "    df1[col] = df1[col].map(dic)\n",
    "    df1[col] = df1[col].astype(\"category\")\n",
    "    df2[col] = df2[col].map(dic)\n",
    "    df2[col] = df2[col].astype(\"category\")\n",
    "    return df1,df2\n",
    "\n",
    "def remove_special(df1,df2,col,tops,inplace = -1):\n",
    "    idx_sets = set(df1[col].value_counts().head(tops).index)\n",
    "\n",
    "    def helper(x):\n",
    "        if x in idx_sets:\n",
    "            return x\n",
    "        else:\n",
    "            return inplace\n",
    "\n",
    "    df1[col] = df1[col].apply(helper)\n",
    "    df2[col] = df2[col].apply(helper)\n",
    "    return df1, df2\n",
    "\n",
    "def process_sp_cate(df1,df2,col): \n",
    "    if col == \"apptype\":\n",
    "        df1, df2 = remove_special(df1, df2, col, 75, -1)\n",
    "    if col == \"media_id\":\n",
    "        df1, df2 = remove_special(df1, df2, col, 200, -1)\n",
    "    if col == \"version\":\n",
    "        df2[col] = df2[col].replace(\"20\", \"0\").replace(\"21\", \"0\")\n",
    "    if col == \"lan\":\n",
    "        lan_set = set(df1[col].value_counts().head(12).index)\n",
    "        def foreign_lan(x):\n",
    "            native_lan = {'zh-CN', 'zh', 'cn', 'zh_CN', 'Zh-CN', 'zh-cn', 'ZH', 'CN', 'zh_CN_#Hans'}\n",
    "            if x in native_lan:\n",
    "                return 0\n",
    "            elif x == \"unk\":\n",
    "                return 2\n",
    "            else:\n",
    "                return 1\n",
    "        df1[\"f_lan\"] = df1[\"lan\"].apply(foreign_lan)\n",
    "        df2[\"f_lan\"] = df2[\"lan\"].apply(foreign_lan)\n",
    "        def helper_lan(x):\n",
    "            if x in lan_set:\n",
    "                return x\n",
    "            else:\n",
    "                return \"unk\"\n",
    "        df1[col] = df1[col].apply(helper_lan)\n",
    "        df2[col] = df2[col].apply(helper_lan)\n",
    "\n",
    "    if col == \"package\":\n",
    "        df1, df2 = remove_special(df1, df2, col, 800, -1)\n",
    "\n",
    "    if col == \"fea1_hash\":\n",
    "        df1, df2 = remove_special(df1, df2, col, 850, -1)\n",
    "\n",
    "    if col == \"fea_hash\":\n",
    "        df1, df2 = remove_special(df1, df2, col, 850, -1)\n",
    "    df1, df2 = process_cate(df1, df2, col)\n",
    "    return df1,df2\n",
    "\n",
    "def process_osv(df1, df2):\n",
    "    def helper(x):\n",
    "        x = str(x)\n",
    "        if not x:\n",
    "            return -1\n",
    "        elif x.startswith(\"Android\"):\n",
    "            x = str(re.findall(\"\\d{1}\\.*\\d*\\.*\\d*\",x)[0])\n",
    "            return x\n",
    "        elif x.isdigit():\n",
    "            return x\n",
    "        else:\n",
    "            try:\n",
    "                x = str(re.findall(\"\\d{1}\\.\\d\\.*\\d*\", x)[0])\n",
    "                return x\n",
    "            except:\n",
    "                return 0\n",
    "    df1.osv = df1.osv.apply(helper)\n",
    "    df2.osv = df2.osv.apply(helper)\n",
    "\n",
    "    osv_set = set(df1[\"osv\"].value_counts().head(70).index)\n",
    "    def helper2(x):\n",
    "        if x in osv_set:\n",
    "            return x\n",
    "        else:\n",
    "            return 0\n",
    "    df1[\"osv\"] = df1[\"osv\"].apply(helper2)\n",
    "    df2[\"osv\"] = df2[\"osv\"].apply(helper2)\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df1.osv = le.fit_transform(df1.osv.astype(\"str\"))\n",
    "    df1[\"osv\"] = df1[\"osv\"].astype(\"category\")\n",
    "    df2.osv = le.transform(df2.osv.astype(\"str\"))\n",
    "    df2[\"osv\"] = df2[\"osv\"].astype(\"category\")\n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(df1,df2):\n",
    "    #缺失值填补\n",
    "    c1 = df1.dev_width.notnull()\n",
    "    c2 = df1.dev_height.notnull()\n",
    "    c3 = df1.dev_ppi.isna()\n",
    "    c4 = df1.dev_ppi.notnull()\n",
    "    df1[\"noppi\"] = c1 & c2 & c3\n",
    "    df1[\"notnull\"] = c1 & c2 & c4\n",
    "    \n",
    "    predict = df1[[\"apptype\", \"carrier\", \"dev_height\", \"dev_ppi\", \"dev_width\", \"media_id\", \"ntt\", \"noppi\", \"notnull\"]]\n",
    "    \n",
    "    df_notnans = predict[predict[\"notnull\"] == True]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df_notnans[[\"apptype\", \"carrier\", \"dev_height\", \"dev_width\", \"media_id\", \"ntt\"]], df_notnans[\"dev_ppi\"],\n",
    "        train_size=0.75, random_state=6)\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=40, random_state=0, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    score = rf.score(X_test, y_test)\n",
    "    \n",
    "    df_nans = predict[predict[\"noppi\"] == True].copy()\n",
    "    df_nans[\"dev_ppi_pred\"] = rf.predict(df_nans[[\"apptype\", \"carrier\", \"dev_height\", \"dev_width\", \"media_id\", \"ntt\"]])\n",
    "    df1 = pd.merge(df1,df_nans[[\"dev_ppi_pred\"]],on = \"sid\",how = \"left\")\n",
    "    \n",
    "    c1 = df2.dev_width.notnull()\n",
    "    c2 = df2.dev_height.notnull()\n",
    "    c3 = df2.dev_ppi.isna()\n",
    "    c4 = df2.dev_ppi.notnull()\n",
    "    df2[\"noppi\"] = c1 & c2 & c3\n",
    "    df2[\"notnull\"] = c1 & c2 & c4\n",
    "    \n",
    "    predict_test = df2[\n",
    "        [\"apptype\", \"carrier\", \"dev_height\", \"dev_ppi\", \"dev_width\", \"media_id\", \"ntt\", \"noppi\", \"notnull\"]]\n",
    "    df_nans = predict_test[predict_test[\"noppi\"] == True].copy()\n",
    "    df_nans[\"dev_ppi_pred\"] = rf.predict(\n",
    "        df_nans[[\"apptype\", \"carrier\", \"dev_height\", \"dev_width\", \"media_id\", \"ntt\"]])\n",
    "    df2 = pd.merge(df2, df_nans[[\"dev_ppi_pred\"]], on=\"sid\", how=\"left\")\n",
    "    \n",
    "    def fill_pii(df):\n",
    "        a = df.dev_ppi.fillna(0).values\n",
    "        b = df.dev_ppi_pred.fillna(0).values\n",
    "        c = []\n",
    "        # print(a,b)\n",
    "        for i in range(len(a)):\n",
    "            c.append(max(a[i], b[i]))\n",
    "        c = np.array(c)\n",
    "        df[\"final_ppi\"] = c\n",
    "        df[\"final_ppi\"][df[\"final_ppi\"] == 0] = None\n",
    "        return df\n",
    "    df1 = fill_pii(df1)\n",
    "    df2 = fill_pii(df2)\n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(df1, df2):\n",
    "    def divided(x):\n",
    "        if x % 40 == 0:\n",
    "            return 2\n",
    "        elif not x:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df1[\"160_height\"] = df1.dev_height.apply(divided)\n",
    "    df2[\"160_height\"] = df2.dev_height.apply(divided)\n",
    "    df1[\"160_width\"] = df1.dev_width.apply(divided)\n",
    "    df2[\"160_width\"] = df2.dev_width.apply(divided)\n",
    "    df1[\"160_ppi\"] = df1.final_ppi.apply(divided)\n",
    "    df2[\"160_ppi\"] = df2.final_ppi.apply(divided)\n",
    "    df1[\"hw_ratio\"] = df1.dev_height / df1.dev_width\n",
    "    df2[\"hw_ratio\"] = df2.dev_height / df2.dev_width\n",
    "    df1[\"hw_matrix\"] = df1.dev_height * df1.dev_width\n",
    "    df2[\"hw_matrix\"] = df2.dev_height * df2.dev_width\n",
    "    df1[\"inch\"] = (df1.dev_height ** 2 + df1.dev_width ** 2) ** 0.5 / df1.final_ppi\n",
    "    df2[\"inch\"] = (df2.dev_height ** 2 + df2.dev_width ** 2) ** 0.5 / df2.final_ppi\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = read_file()\n",
    "for col in [\"location\", \"os\", \"ntt\", \"cus_type\"]:\n",
    "    train, test = process_cate(train,test,col)\n",
    "train, test = dict_cate(train,test,\"carrier\",{-1.0:-1, 0.0:0, 46000.0:1, 46001.0:2, 46003.0:3})\n",
    "for col in [\"apptype\", \"media_id\", \"version\", \"lan\", \"package\", \"fea1_hash\", \"fea_hash\"]:\n",
    "    train, test = process_sp_cate(train,test,col)\n",
    "train, test = process_osv(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = rf(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = feature(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['android_id', 'apptype', 'carrier', 'dev_height', 'dev_ppi',\n",
    "       'dev_width','lan', 'media_id', 'ntt', 'os', 'osv', 'package',\n",
    "       'timestamp', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type',\n",
    "       'day', 'hour', 'minute', 'f_lan', 'noppi', 'notnull',\n",
    "       'dev_ppi_pred', 'final_ppi', '160_height', '160_width', '160_ppi',\n",
    "       'hw_ratio', 'hw_matrix', 'inch']\n",
    "\n",
    "cate_feat = ['apptype', 'carrier', 'lan', 'media_id', 'ntt', 'os', \n",
    "       'osv', 'package','timestamp', 'version', 'fea_hash', 'location', 'fea1_hash', 'cus_type',\n",
    "       'day', 'hour', 'minute', 'f_lan', 'noppi', 'notnull']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type():\n",
    "    model = lgb.LGBMRegressor(\n",
    "        num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, \n",
    "        max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2021,\n",
    "        n_estimators=600, subsample=0.9, colsample_bytree=0.7,)\n",
    "    return model\n",
    "\n",
    "def predict_model(train,test, features, cate_feat):\n",
    "    df1 = train.copy()\n",
    "    df2 = test.copy()\n",
    "    model = get_model_type()\n",
    "    model.fit(df1[features], df1[\"label\"], categorical_feature = cate_feat, verbose = 100)\n",
    "    df2[\"label\"] = model.predict(df2[features])\n",
    "    predict = df2[[\"label\"]]\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"android_id\"]= train[\"android_id\"].astype(\"int\")\n",
    "test[\"android_id\"]= test[\"android_id\"].astype(\"int\")\n",
    "\n",
    "train = train.drop([\"time\"],axis=1)\n",
    "test = test.drop([\"time\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440682</th>\n",
       "      <td>0.072827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606824</th>\n",
       "      <td>0.732386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774642</th>\n",
       "      <td>0.021766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742535</th>\n",
       "      <td>0.038959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689686</th>\n",
       "      <td>0.940323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165373</th>\n",
       "      <td>0.943027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444115</th>\n",
       "      <td>0.956365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134378</th>\n",
       "      <td>0.941794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700238</th>\n",
       "      <td>0.983145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201539</th>\n",
       "      <td>0.969777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            label\n",
       "sid              \n",
       "1440682  0.072827\n",
       "1606824  0.732386\n",
       "1774642  0.021766\n",
       "1742535  0.038959\n",
       "1689686  0.940323\n",
       "...           ...\n",
       "1165373  0.943027\n",
       "1444115  0.956365\n",
       "1134378  0.941794\n",
       "1700238  0.983145\n",
       "1201539  0.969777\n",
       "\n",
       "[150000 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict_model(train,test,features,cate_feat)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79648\n",
       "1    70352\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def helper(x):\n",
    "        if x > 0.5:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "predict[\"label\"] = predict[\"label\"].apply(helper)\n",
    "predict[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257760\n",
       "1    242240\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1440682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1606824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1774642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1742535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1689686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>1165373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>1444115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>1134378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>1700238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>1201539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sid  label\n",
       "0       1440682      0\n",
       "1       1606824      1\n",
       "2       1774642      0\n",
       "3       1742535      0\n",
       "4       1689686      1\n",
       "...         ...    ...\n",
       "149995  1165373      1\n",
       "149996  1444115      1\n",
       "149997  1134378      1\n",
       "149998  1700238      1\n",
       "149999  1201539      1\n",
       "\n",
       "[150000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = predict.reset_index(drop = False)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.to_csv(\"predicts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
